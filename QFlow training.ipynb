{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Importing the QFlow class\n",
    "In Python 3.6 this might return a warning but it can be ignored (it does not affect the accuracy or performance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the QFlow class\n",
    "import os \n",
    "import QFlow_class\n",
    "qf = QFlow_class.QFlow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create the random subregions for training\n",
    "This cell needs to be run only once, as it stores created training data set locally in the `Data/sub_images`. Argument `sub_size` allows to set the subregion size. It needs to be consistent with the `cnn_model_fn`. \n",
    "\n",
    "The progress of extracting and slicing data is visualized with a progress bar. Total time to generate 10 subregions, 30 x 30 pixels, per each data file on a 2017 MacBook Pro is about 7 minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the size of subregions\n",
    "sub_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# give a path to where the raw_data.zip file is -- if the raw_data.zip file is in the same folder as QFlow training use \n",
    "path_data = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create the files for training, 10 subregions per image \n",
    "# this needs to be executed only once\n",
    "qf.slice_data(sub_size = sub_size, path_data = path_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2a: Previewing the subregions\n",
    "This cell allows to preview the training data together with the label for a given subregion. The format of the label is `[SC, QPC, SD, DD]` and it represents the percentage of the subregion area taken by a gien state.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qf.data_preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Definition of the learning network\n",
    "\n",
    "Network parameters, such as the number of convolutional and pooling layers and the number and size of dense layers can be modified to improve the performance of the network. With the default architecture, on a 2017 MacBook Pro the network trains on 30 x 30 pixel subregions to the accuracy of about 96% in about 10 minutes, with accuracy defined as the percentage of correctly classified subregions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Convolutional Neural Network Estimator for 5-gates device.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    \n",
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "    input_layer = tf.cast(tf.reshape(features[\"x\"], [-1, sub_size, sub_size, 1]), tf.float32)\n",
    "\n",
    "    # Convolutional Layer\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",        # preserves width and height\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # Flatten tensor into a batch of vectors\n",
    "    pool2_flat = tf.contrib.layers.flatten(pool1)\n",
    "\n",
    "    # Dense Layers\n",
    "    dense0 = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout0 = tf.layers.dropout(inputs=dense0, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    dense1 = tf.layers.dense(inputs=dropout0, units=512, activation=tf.nn.relu)\n",
    "    dropout1 = tf.layers.dropout(inputs=dense1, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    dense2 = tf.layers.dense(inputs=dropout1, units=128, activation=tf.nn.relu)\n",
    "    dropout2 = tf.layers.dropout(inputs=dense2, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout2, units=4)\n",
    "\n",
    "    predictions = {\n",
    "        \"state\": tf.argmax(input=logits, axis=1),\n",
    "        \"probabilities\": tf.cast(tf.nn.softmax(logits , name=\"softmax_tensor\"), tf.float64)\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.mean_squared_error(labels=labels, predictions=tf.nn.softmax(logits))\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "        \n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\"accuracy\": tf.metrics.accuracy(labels=tf.argmax(labels, axis=1), \\\n",
    "                                                       predictions=predictions[\"state\"])}\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Execution of training and evaluation on simulated data\n",
    "\n",
    "The code reads the subregion data and splits it into two sets (90% for training, 10% for evaluation). Then, using the `cnn_model_fn`, the network is trained to distinguish between single dots, double dots, short circuit and barrier states. The trained network is stored in the `Data/trained_model` folder (created during training). To re-train the network on a new data set this folder needs to be removed or emptied. The outcome from the network is a probability vector in the format `[SC, QPC, SD, DD]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the estimator and a place to store the trained network\n",
    "state_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=\"Data/trained_model\")\n",
    "\n",
    "#train the network\n",
    "qf.train_net(classifier=state_classifier, batch_size=50, steps=5000)\n",
    "qf.eval_net(classifier=state_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Visualization of the classification accuracy for evaluation\n",
    "A histogram showing the comparison of true data labels from the evaluation set (evals) and the labels predicted by the trained network (preds). The vertical axis represents the number of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qf.evaluation_visual()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Evaluation of the trained network on experimental data\n",
    "\n",
    "The code reads the provided experimental data from a folder `Data/exp_data` and then applies the trained network to classify each image. The README file explains how data needs to be formated to be compatible with the network.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the estimator\n",
    "state_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=\"Data/trained_model\")\n",
    "\n",
    "# evaluate the experimental data\n",
    "exp_preds = qf.eval_exp(scaling = 10**2, classifier=state_classifier)\n",
    "qf.exp_visual(exp_preds = exp_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
